{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5c72fb",
   "metadata": {},
   "source": [
    "# Тестирование модели (загруженной локально)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7531404d",
   "metadata": {},
   "source": [
    "## 1. Загрузка и использование с **AutoTokenizer** и **AutoModelForSequenceClassification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b881397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mycode\\classifier-emotions-text-ru\\.venv-classifier\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f60a0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> Используем устройство: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\" >> Используем устройство: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "690d848a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cointegrated/rubert-tiny2-cedr-emotion-detection\"\n",
    "model_path= \"../models/rubert-tiny2-cedr-emotion-detection/\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    use_fast=True,   # Используем быстрый токенизатор\n",
    "    truncation=True, # Обрезаем длинные тексты\n",
    "    max_length=512,  # Максимальная длина (у RuBERT обычно 512)\n",
    "    return_tensors=\"pt\"  # Возвращаем тензоры PyTorch\n",
    ")\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6f72c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'no_emotion', 1: 'joy', 2: 'sadness', 3: 'surprise', 4: 'fear', 5: 'anger'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = model.config.id2label\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7fe8219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('joy', 0.9986925721168518)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Я очень рад, что ты вернулся!\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "    text,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "\n",
    "predicted_class_id = torch.argmax(probs, dim=-1).item()\n",
    "predicted_label = id2label[predicted_class_id]\n",
    "confidence = probs[0][predicted_class_id].item()\n",
    "predicted_label, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d7c466",
   "metadata": {},
   "source": [
    "## 2. Загрузка и использование с **transformers.pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcea6876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10146717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'joy', 'score': 0.9798190593719482}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\n",
    "    \"text-classification\", \n",
    "    model=model_path,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "text = \"Я очень рад, что ты вернулся!\"\n",
    "\n",
    "with torch.no_grad():\n",
    "    result = classifier(text)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a81168",
   "metadata": {},
   "source": [
    "## 3. Обращение при помощи **InferenceClient** (*HF Inference API*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06625a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc68a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<InferenceClient(model='cointegrated/rubert-tiny2-cedr-emotion-detection', timeout=None)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = InferenceClient(\n",
    "    model=model_name,\n",
    "    provider=\"hf-inference\",\n",
    "    api_key=os.environ[\"HF_TOKEN\"],\n",
    ")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b090197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextClassificationOutputElement(label='joy', score=0.9798190593719482),\n",
       " TextClassificationOutputElement(label='sadness', score=0.023603854700922966),\n",
       " TextClassificationOutputElement(label='no_emotion', score=0.011824214830994606),\n",
       " TextClassificationOutputElement(label='surprise', score=0.010615072213113308),\n",
       " TextClassificationOutputElement(label='anger', score=0.008691806346178055)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Я очень рад, что ты вернулся!'\n",
    "\n",
    "result = client.text_classification(\n",
    "    text=text\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453adb2c",
   "metadata": {},
   "source": [
    "**client.text_classification**\n",
    "\n",
    "- **Returns**:\n",
    "    * `List[TextClassificationOutputElement]`: a list of [`TextClassificationOutputElement`]\n",
    "    items containing the predicted label and associated probability.\n",
    "\n",
    "- **Raises**:\n",
    "    * [`InferenceTimeoutError`]:\n",
    "        If the model is unavailable or the request times out.\n",
    "    * `HTTPError`:\n",
    "        If the request fails with an HTTP error status code other than HTTP 503."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
